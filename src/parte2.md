# I. Introducción

Antes de comenzar a “hacer estadística”, necesitamos tomarnos un rato para pensar por qué existe esta disciplina, de dónde viene, para qué sirve y qué tipo de conocimiento realmente nos permite construir. Esta primera parte del libro busca poner en contexto la estadística: no como un castigo impuesto por alguna deidad malvada, ni sólo como conjunto de fórmulas o reglas, sino como una forma particular de ver, ordenar e interpretar el mundo.

Si bien podemos usar la estadística como una herramienta técnica, también valdría la pena entenderla como parte de una historia más larga, en la que las personas hemos intentado, con más o menos éxito, responder algunas de las preguntas más fundamentales que existen: ¿qué sé?, ¿cómo lo sé?, ¿puedo confiar en esto?, ¿cómo comparo cosas?, ¿qué tan seguro puedo estar de lo que estoy afirmando?, o ¿cómo distingo cuándo es válido lo que otros afirman?

Esta parte se divide en tres capítulos. En el primero, “Conocer”, revisamos el trasfondo conceptual, histórico y filosófico que da sentido a la estadística como disciplina. En el segundo, “Organizar”, veremos cómo convertir fenómenos del mundo en datos legibles. Y en el tercero, “Resumir”, exploraremos las primeras herramientas para describir esos datos de manera clara y útil.

## 1. Antecedentes

Antes de recolectar, ordenar o analizar datos, necesitamos saber por qué lo haríamos. Qué sentido tiene. Cuál es el rol que cumple la estadística en la construcción del conocimiento y en nuestra vida cotidiana. Este capítulo se detiene en esa pregunta inicial: ¿por qué estadística?

### 1.1 Porqué

Exploraremos tres ejes: razones para aprenderla, de las más prácticas a las más existenciales; su historia como disciplina vinculada al poder, a la ciencia y a la toma de decisiones; y finalmente, su lugar dentro de las grandes preguntas filosóficas sobre cómo conocemos el mundo. Todo esto con el ánimo de situar a la estadística como una herramienta que nos puede ayudar a pensar y conocer mejor.

#### Motivación

La pregunta "¿por qué aprender estadística?" tiene muchas respuestas posibles. Algunas pueden ser bien mundanas:

- *Porque está en la malla de mi carrera.*
- *Porque necesito pasar la asignatura.*
- *Porque me carga, pero me la tengo que bancar.*
- *Porque si no la hago ahora, me atrasaré en la carrera.*
- *Porque el profe es simpático.* (dijo nadie nunca)

Y sí, todas esas pueden ser respuestas válidas si son honestas. No las voy a juzgar. A veces, una motivación pragmática basta para prender el motor. Entraste, ya estás aquí. Démosle igual.

También existen razones más relacionadas con un honesto interés por el desarrollo profesional:

- *Porque quiero entender mejor los papers.*
- *Porque quiero hacer investigación.*
- *Porque me gustaría tomar decisiones con base en datos.*
- *Porque me interesa trabajar con encuestas, evaluaciones, programas sociales.*
- *Quizás me ayude a encontrar pega después.*  
  ([Informe OCDE: Getting Skills Right - Chile, 2018](https://www.oecd.org/content/dam/oecd/en/publications/reports/2018/04/getting-skills-right-chile_g1g8b67d/9789264293151-en.pdf))

Y, además, están las razones más existenciales, filosóficas o incluso políticas:

- *Porque quiero entender mejor cómo funciona el mundo.*
- *Porque quiero saber cuándo me están tratando de engañar.*
- *Porque quiero tener herramientas para ser una persona más crítica.*
- *Porque creo que los datos no son neutros y quiero aprender a leerlos bien.*

Todas esas razones son válidas. Ninguna es completamente mejor que otra. Lo importante es que te permita conectar con lo que estás a punto de aprender. Y con suerte, que te haga sentido más allá de la prueba.

Además, estas razones pueden cambiar con el tiempo. A veces uno entra solo para cumplir, pero algo se activa en el camino. Una pregunta que te queda resonando. Una herramienta que te hace clic. Una curiosidad que se despierta. Y sin darte cuenta, pasas de aguantar la estadística... a convertirte en el profe (quién sabe).

Durante la pandemia, le hice esta misma pregunta —¿por qué es importante estudiar estadística (en una carrera como psicología?)— a un grupo de colegas que quiero mucho. Son parte de la **Asociación Chilena de Metodología, Medición y Evaluación (ACMME)** (https://acmme.cl/), que es una sociedad científica legalmente constituida de la cuál soy miembro fundador, pero -honestamente- básicamente es un grupo de amigos/as profes de estadística o áreas cercanas (y sí, suena casi igual que ACME, como en los dibujos del Coyote y el Correcaminos. No es coincidencia).

Les pedí que respondieran de forma breve —aunque no todos hicieron caso, igual se les agradece. Una de las respuestas se cortó misteriosamente en el archivo original, pero quedó el resto.  
Después pensé en repetir la idea con más tiempo y producción... pero se acabó la pandemia, y ya era raro volver a pedirlo. Quizás algún día lo retome con más calma. Por ahora, les dejo ese registro (https://youtu.be/H7utyKRTDWM).

<iframe width="560" height="315" src="https://www.youtube.com/embed/H7utyKRTDWM" title="¿Por qué estudiar estadística? - ACMME 2020" frameborder="0" allowfullscreen></iframe>

#### Historia

Les juro que la estadística no nació porque sólo alguien malvado tenía ganas de obligar a los estudiantes de Ciencias Sociales a seguir estudiando matemáticas, como si no hubiera sido suficientemente terrible en la educación media. Nació mucho antes, cuando la humanidad empezó a contar cosas importantes. Cuántos animales cazó la tribu. Cuánta cebada había almacenada. Cuántos hijos sobrevivieron al invierno.

Desde Mesopotamia a Egipto, desde los censos imperiales hasta las cuentas de impuestos, contar fue siempre poder. La palabra “estadística” viene justamente de “status”, el Estado. Porque para gobernar, había que contar: personas, recursos, guerras, muertes.

Pero la estadística como disciplina más matemática tiene su auge entre los siglos XIX y XX. Ahí aparecen nombres como:

- **Gauss**, con su famosa curva normal.
- **Galton**, obsesionado con la herencia y la regresión hacia la media.
- **Pearson**, el fanático de la correlación (y de graficarlo todo).
- **Fisher**, que nos dio los fundamentos de la inferencia moderna.
- **Tukey**, que puso sobre la mesa el análisis exploratorio como práctica legítima.

Hoy la estadística está por todas partes. En la salud pública, en la psicología, en los estudios sociales, en los algoritmos que deciden qué ves en redes sociales. Vivimos en una era donde el problema ya no es la escasez de datos, sino su exceso. Y saber analizarlos es una forma de alfabetización clave.

#### Conocimiento

Una de las preguntas más viejas del mundo es: ¿cómo sabemos lo que sabemos? ¿De dónde viene lo que llamamos conocimiento? ¿Es confiable? ¿Podemos distinguir entre saber algo y creerlo nomás porque nos suena bonito?

Esa pregunta, que parece tan básica, ha obsesionado a filósofos, científicos, poetas y nerds de todas las épocas. Y aunque la estadística parece estar más cerca de las matemáticas que de la filosofía, en realidad está profundamente atravesada por esa búsqueda. Porque ¿qué otra cosa es recolectar, organizar y analizar datos, sino un intento por conocer de manera más clara, más rigurosa, más compartida?

Volvamos un poco atrás. En la Grecia antigua, **Pitágoras** andaba diciendo que todo era número. **Platón**, que había un mundo ideal, perfecto, y que lo que veíamos era apenas una sombra de ese mundo verdadero. **Aristóteles**, que la clave estaba en observar, clasificar y sistematizar lo que tenemos aquí, en este mundo concreto, sin tanta volada mística. Platón pensaba que el conocimiento era recordar ideas puras que ya estaban en el alma. Aristóteles, más pragmático, decía que había que mirar, medir, observar. Los dos sentaron bases: uno para la deducción lógica, el otro para el empirismo. Y de esa tensión nace todo lo demás. Uno apuntaba pa’ arriba, el otro pa’ abajo. Y si somos honestos, ambos tenían algo de razón (y ambos estaban equivocados en un montón de cosas).

Siglos más tarde, aparecen otros personajes. **Descartes**, por ejemplo, en plena modernidad, se cuestionaba si podía estar seguro de algo, incluso su existencia. "Pienso, luego existo", concluyó, pero mientras tanto también estaba inventando el plano cartesiano, que nos permite ubicar cosas en el espacio con dos ejes. Hermoso crossover entre filosofía y geometría. Estaba preguntándose qué es real, mientras diseñaba un sistema para ubicar lo real. Un visionario multitasking.

Después vinieron **Locke**, **Hume**, **Kant**... cada uno aportando piezas al rompecabezas. Locke decía que nacíamos como una hoja en blanco. Hume, que toda nuestra mente se basa en costumbre y asociación. Kant, que la mente misma organiza la experiencia según ciertas categorías. A cada uno le parecía que el otro estaba un poco perdido, pero de esa pelea conceptual surgió una idea potente: que conocer no es solo mirar o solo pensar, sino una mezcla densa entre experiencia y estructura.

Y mientras todos ellos peleaban con palabras, otros lo hacían con telescopios. En la revolución científica, personajes como **Francis Bacon**, **Galileo Galilei** y **Isaac Newton** empujaron una idea distinta: que podíamos conocer el mundo mediante observación sistemática, medición, y leyes que se verifican empíricamente. Bacon defendía el método inductivo, Galileo medía bolas rodando por planos inclinados, Newton modelaba el movimiento de los planetas con fórmulas matemáticas. Ciencia como forma de ordenar el caos. Se supone que no eran filósofos, pero respondían la misma pregunta: ¿cómo saber?

Así surgió lo que hoy llamamos método científico. Observación → hipótesis → experimentación → conclusión. Y aunque se ve lindo en esquemas de PowerPoint, en la práctica siempre fue más sucio, más torpe, más humano. Las ideas no siempre se confirman, los datos no siempre calzan, y los científicos no siempre son objetivos.

Con el tiempo, el entusiasmo por la ciencia como camino al conocimiento perfecto derivó en una corriente llamada positivismo, que creía que todo podía medirse, predecirse y explicarse con suficiente método. Una visión optimista, pero que también pecaba de ingenua. No todo lo importante se deja medir. No todos los fenómenos siguen reglas fijas. Y no todo dato es puro.

Personalmente, me siento más cómodo reconociendo que el conocimiento es incierto, cambiante, que está en construcción constante. Que no tenemos verdades absolutas, pero sí herramientas para distinguir ideas más o menos razonables, más o menos útiles. Que lo importante no es tener razón, sino saber cuándo estamos equivocados.

Ahí entra **Karl Popper**. No porque haya inventado la ciencia (ja ja), sino porque propuso una forma elegante de entenderla. Popper decía que las teorías científicas no son valiosas por ser verdaderas, sino por ser **refutables**. Es decir, una teoría es científica si podemos imaginar una situación en la que pueda fallar. Si no hay forma de que se equivoque, entonces no es ciencia: es dogma.

A esta idea la llamó **falsacionismo**. Y sigue siendo una de las piedras angulares del pensamiento científico actual. Una buena teoría no es la que explica todo, sino la que se arriesga a fallar.

El filósofo **Bertrand Russell**, mentor parcial de Popper, ilustró esta idea con un ejemplo que me gusta mucho: imaginá que yo digo que hay una tetera flotando en el espacio, entre la Tierra y Marte. Pero es tan pequeña y está tan lejos que ningún telescopio podrá jamás detectarla. ¿Tiene sentido creer en esa tetera? ¿Hay alguna forma de demostrar que no está ahí? No. ¿Entonces debo creer que sí está ahí? Tampoco. Lo que no puede refutarse no es necesariamente falso... pero tampoco tiene mucho valor como conocimiento.

Aunque Rusell pensaba en esta idea como una metafora para Dios (era SUPER áteo), Popper aplicó este criterio a muchas teorías no religiosas influyentes de su época. Criticaba el psicoanálisis, el marxismo y algunas corrientes del positivismo porque, según él, podían explicar cualquier cosa, acomodando sus postulados para que siempre parecieran tener razón. Eso las hacía impermeables al error. Y por tanto, menos científicas.

Eso no significa que todo el psicoanálisis sea basura, ojo. Muchas ideas valiosas han salido de ahí. Por ejemplo, la teoría del apego —clave en psicología del desarrollo— nace desde ese marco. Pero la crítica no es a los contenidos, sino al estilo de razonamiento: cuando una teoría tiene respuesta para todo, y nunca admite estar equivocada, es momento de sospechar.

La ciencia, según esta mirada, no avanza confirmando cosas una y otra vez, sino **descartando lo que no funciona**. Antes pensábamos que la Tierra era el centro del universo. No sólamente porque como humanidad seamos TAN egocéntricos, sino porque parecía así. El sol sale por el este, se pone por el oeste, y uno se siente muy quieto. Pero al observar sistemáticamente, los datos empezaron a no cuadrar. Surgieron nuevas teorías. Las viejas se modificaron o murieron.

Así funciona el conocimiento: se ajusta, se transforma, se discute. No es absoluto, pero tampoco es caprichoso. Si una idea no cambia nunca, aunque sus predicciones no se cumplan, o si ni siquiera es capaz de generar predicciones contrastables, entonces no es ciencia. Es otra cosa. Puede ser filosofía, ideología, religión, narrativa… pero no ciencia. Y eso no necesariamente las invalida, pero las pone en otro plano. El conocimiento científico, en cambio, vive y respira en la frontera entre lo que sabemos y lo que estamos dispuestos a revisar.

Y acá entra la estadística. Porque en este contexto —un mundo lleno de datos, de afirmaciones, de ideas que compiten— necesitamos herramientas que nos permitan observar patrones, contrastar hipótesis, estimar cuánto confiar en un resultado. La estadística no reemplaza al pensamiento crítico: lo **afila**. No garantiza respuestas correctas, pero sí permite hacer mejores preguntas, con mejores datos, y con mayor conciencia de sus limitaciones. Nos obliga a preguntarnos: ¿qué tan raro es este resultado?, ¿cuánta variación hay?, ¿qué tanto podemos generalizar?, ¿qué tan probable es que esto sea solo ruido?

La estadística no es la enemiga de la filosofía. Es su hija rebelde (pero igual amigui). Nació de sus preguntas, pero eligió intentar responder con otras herramientas. Donde la filosofía planteó dudas fundamentales sobre cómo conocer, la estadística dijo: “intentémoslo así”. Y no se fue por el camino fácil: abrazó la incertidumbre, se acostumbró a los márgenes de error, al “más o menos”. No busca certezas absolutas, sino probabilidades razonables. Y, como buena hija, no solo respondió las preguntas que le plantearon... también le devolvió nuevas preguntas a su madre.

A lo largo del tiempo, algunas de las preguntas más antiguas del pensamiento se han reformulado de maneras nuevas. La filosofía se ha preguntado durante siglos si el alma existe. La estadística, en vez de entrar a debatir esa existencia desde lo metafísico, ha permitido desarrollar escalas que miden experiencias subjetivas de bienestar, actitudes hacia la espiritualidad, o percepciones sobre la conciencia. A través de esos datos, se explora cómo esas vivencias se asocian con otras variables en poblaciones concretas. ¿Estamos hablando todavía del “alma”? Quizás no en el sentido original, pero sí en un terreno más compartible, contrastable y analizable.

<!-- BEGIN:IMG -->

<figure>
    <img src="https://upload.wikimedia.org/wikipedia/commons/1/1b/Phineas_Gage_Cased_Daguerreotype_WilgusPhoto2008-12-19_EnhancedRetouched_Color.jpg" alt="Phineas Gage" width="188">
  <figcaption>
    <p>Phineas Gage, desmitificando la existencia del alma desde 1848™.</p>
  </figcaption>
</figure>

<!-- END:IMG -->

Esto no significa que haya que censurar las preguntas filosóficas. Al contrario: muchas de ellas siguen siendo potentes, necesarias, estimulantes. Pero cuando se traducen en términos que permiten ser observados, medidos, compartidos, se acercan más a lo empírico. Quizás se sacrifica parte de la pregunta original, sí. Pero a cambio ganamos algo con lo que podemos discutir, contrastar, refutar. Algo que puede ser cierto, o puede estar equivocado, pero al menos no es solo opinión con buena dicción.

Otro caso parecido se ve en medicina. Donde antes se debatía si un tratamiento "curaba" o no una enfermedad, hoy la estadística propone una estrategia concreta: se comparan dos grupos similares, se administra el tratamiento solo a uno, se miden los efectos, y se estima si la diferencia es estadísticamente significativa. No garantiza una respuesta absoluta, pero sí permite poner a prueba la eficacia con cierto control. Y también recuerda una verdad incómoda: ningún tratamiento funciona igual para todos, ni el 100% del tiempo. Pero eso no invalida su utilidad.

Eso sí: que algo tenga respaldo estadístico no significa que deba imponerse como verdad absoluta o como política indiscutible. A veces, los resultados son usados con fines ideológicos, autoritarios o comerciales. No es culpa de la estadística: es culpa de cómo se usa. Por eso, también debemos estar preparados para cuestionar los datos mismos. ¿Representan lo que realmente queríamos medir? ¿Ignoran otras consecuencias? ¿Refuerzan desigualdades? Si algo genera daño —aunque haya pasado por un test estadístico— eso también debe poder ser medido, discutido, y si corresponde, revisado.

La estadística no reemplaza la filosofía, ni la política, ni la ética. Pero cuando se usa con honestidad, puede volver esas discusiones más precisas, más abiertas, más útiles. No resuelve todo. Pero permite empezar a separar lo que tiene algo de sentido de lo que simplemente suena fuerte.

Estadística es pensar con los pies en la tierra. Es construir conocimiento a partir de evidencia limitada, pero estructurada. Es buscar regularidades donde reina el caos. Y es saber que incluso esas regularidades pueden cambiar.

Por eso, en lugar de ver la estadística como algo separado de la filosofía o de la ciencia, conviene entenderla como parte del mismo esfuerzo humano por **entender el mundo**. Solo que en vez de depender de argumentos puramente conceptuales, se arma con tablas, gráficos, pruebas y modelos. Es menos sobre tener razón, y más sobre tener razones que puedan ser evaluadas. Y cuando se usa bien, puede transformar preguntas eternas en hipótesis concretas, y convertir sospechas en resultados discutibles, pero útiles.

Es el lenguaje que usamos para conversar con la incertidumbre. Es una forma de conocimiento que reconoce sus límites. Y por eso importa.

Porque sin herramientas como esta, nos quedamos atrapados en el oscurantismo, con el terraplanismo literal... y también con su versión metafórica: esa idea de que el mundo es plano, simple, evidente, binario, y que basta con “sentir que algo es verdad” para actuar como si lo fuera. Nos quedamos con supersticiones con buen marketing. Con ideologías envueltas en palabras edulcoradas o con tono de autoridad. Con frases como “el mercado se regula solo”, “dato mata relato”, o “los niños necesitan más esfuerzo y menos emociones” como si fueran verdades autoevidentes.

Y sí, muchas veces nos quieren vender esas ideas. A veces por ignorancia, otras por locura, otras por plata, odio, ambición, ego, o simplemente por trolear. Hay un mercado grande de humo con PowerPoint. En ese mar revuelto, necesitamos poder **discernir**. Y para eso existen las estadísticas: no como una religión de los números, sino como una caja de herramientas para navegar entre discursos, contrastar afirmaciones, y exigir evidencia antes de entregar confianza.

Pero también hay otro lado: hay avances reales, ideas poderosas que han cambiado el mundo para mejor, hallazgos que han salvado millones de vidas, políticas públicas que redujeron desigualdades, tratamientos que antes no existían, diagnósticos más justos, conocimiento colectivo que crece. Y para poder ver eso —para distinguir el progreso genuino del puro blablá— también necesitamos estadística. Necesitamos saber cuándo algo funciona, cuándo mejora una situación, cuánto impacto tiene una intervención, cómo evoluciona una tendencia, o cuán común es un fenómeno que nos preocupa.

Las estadísticas no son la verdad con mayúscula. Pero sí nos ayudan a afinar nuestra percepción, a organizar el ruido, a construir conocimiento público y discutible. Nos recuerdan que no todo da lo mismo, y que algunas cosas sí se pueden saber mejor.

Por eso este libro. Por eso esta sección. Por eso este capítulo. Porque si queremos pensar críticamente, vivir en sociedad, y tomar decisiones con mayor sabiduría, y sobrevivir como especie... necesitamos estadística (y probablemente es urgente).

### 1.2 Definiciones

Antes de avanzar hacia herramientas, gráficos o fórmulas, tenemos que ordenar el lenguaje. No como quien memoriza un glosario, sino como quien aprende a usar bien las palabras porque entiende que, si no lo hacemos, todo lo que viene después se vuelve turbio. Porque si hablamos enredado, creemos que estamos en desacuerdo... cuando en realidad solo estamos usando los mismos términos para cosas distintas.

La estadística ha sido definida de muchas maneras. Algunos textos clásicos de estadística más "pura" la describen como *el estudio de los métodos para recolectar, presentar, analizar e interpretar datos numéricos obtenidos de observaciones*. Otros, desde un enfoque más aplicado, la definen como *el conjunto de principios y técnicas que nos permiten tomar decisiones informadas a partir del análisis de datos recolectados sistemáticamente*. Ambas son válidas.

Por otro lado, uno de los abuelos de la disciplina, Karl Pearson lanzó una afirmación simple y potente: **“la estadística es la gramática de la ciencia”**. Un statement persuasivo que hace que hasta hoy tengamos que estudiar esto. No se trata solo de técnica: se trata del lenguaje que nos permite hablar con claridad, con estructura, con coherencia dentro del mundo científico. Así como no podés escribir literatura sin saber conjugar verbos, no podés hacer ciencia sin entender cómo se construyen, evalúan y reportan datos.

Pero para efectos de este libro, propongo dos definiciones más compactas. La primera: **la estadística es una herramienta para construir conocimiento a partir de datos**. Porque aunque venga de la matemática, en nuestras disciplinas —psicología, educación, salud, ciencias sociales— la usamos así: como una manera de entender mejor el mundo. La segunda: **es una disciplina que nos enseña cómo recolectar, organizar, analizar e interpretar datos**. Y esas cuatro palabras van a ser protagonistas de todo lo que viene:

- **Recolectar**: cómo diseñamos instrumentos, cómo medimos, cómo obtenemos datos que no sean un chiste.
- **Organizar**: cómo registramos, limpiamos y preparamos esos datos.
- **Analizar**: qué hacemos con ellos una vez que están listos —resúmenes, gráficos, modelos.
- **Interpretar**: cómo entendemos esos resultados en relación a nuestras preguntas.

Ahora bien, no toda la estadística es igual. Existe una estadística teórica —más abstracta, más matemática— que se dedica a estudiar las propiedades de los estimadores, las distribuciones, los supuestos. Pero este libro se enfoca en **estadística aplicada**, es decir, en cómo usamos estas herramientas para responder preguntas reales en investigaciones reales con datos reales (y a veces bastante feos). No vamos a hacer demostraciones con símbolos griegos flotando: vamos a ver qué podemos decir cuando alguien te pasa un Excel con 1000 respuestas.

Y ahí conviene distinguir dos grandes dimensiones dentro de esta caja de herramientas:

Por un lado está la **estadística descriptiva**, que se dedica a ordenar el caos. Como seres humanos, nuestra capacidad de procesamiento de información es limitada. Podemos entender a un grupo de personas si son poquitos —¿siete sujetos?, ok, los leo uno por uno—. Pero si son 100, 1000 o un millón, necesito ayuda. Necesito saber cómo se comporta el grupo sin leer cada fila. La estadística descriptiva nos da eso: resúmenes, visualizaciones, medidas clave. Es como hacer zoom out y poder ver el panorama general. Es el foco de este libro.

Y por otro lado está la **estadística inferencial**, que aparece cuando queremos decir algo más allá de lo que tenemos. Cuando queremos extrapolar lo observado en una muestra y hacer afirmaciones (con cierto margen de error) sobre una población más grande. Inferir implica riesgo, pero también potencia. No es el foco de este libro, pero iremos anticipando su necesidad, y cuando convenga, daremos algunos vistazos.

Para hablar bien de esto, necesitamos entender qué significa “población” y “muestra”. Si yo quiero estudiar todos los Pokémon existentes —actualmente 1025—, esa sería mi población. Si me concentro solo en los originales de la primera generación (n = 151), esa sería una muestra. Idealmente, una muestra representa bien a su población: no basta con que sea más chica, tiene que ser seleccionada de manera que nos diga algo útil. Lo mismo pasa si estudio a todos los adolescentes chilenos: no puedo simplemente encuestar a los que tengo cerca y asumir que eso vale para todo el país. La idea de “muestra” está amarrada a esa responsabilidad: reducir sin distorsionar. Cómo conseguir o distinguir una "buena muestra" es una tarea que será más pertinente discutir con detalle cuando hablemos de estadística inferencial, pero valdrá la pena tenerlo en mente.

También esta distinción nos lleva a algo más grande. Lo que hacemos con estadística se enmarca en una práctica más amplia: **la investigación cuantitativa**. Es un enfoque que busca responder preguntas mediante la recolección y análisis de datos numéricos. A veces usamos encuestas, a veces pruebas, a veces observaciones codificadas. Pero siempre hay datos. Y esos datos se analizan con estadística.

Existe también la **investigación cualitativa**, que es otra forma de abordar el conocimiento, centrada en narrativas, significados, experiencias en profundidad. En mi opinión puede ser un poderoso complemento. Pero no es el foco de este libro. Acá trabajaremos todo el tiempo dentro de la lógica cuantitativa. Y aunque no hablaremos de diseño de investigaciones en detalle (eso es materia de un curso de metodología), algunas de esas ideas van a aparecer igual, porque sin preguntas bien planteadas, ningún análisis sirve.

En este contexto, los estudios se hacen con datos. Y esos datos provienen de **sujetos** (también llamados unidades de análisis), a quienes observamos a través de la medición o registro de **variables**. Cada variable representa una característica que puede cambiar entre sujetos: edad, sexo, nivel de estrés, ingreso mensual, tiempo de reacción, color favorito. Si no cambia, no es variable.

Un **dato**, entonces, es un valor específico de una variable para un sujeto, en el contexto de un estudio cuantitativo. Por ejemplo: “edad = 19 años” para un estudiante universitario. Un dato puede ser un número o un valor que tiene un significado, un contexto. En lenguaje técnico podríamos decir que un dato es una celda de una matriz de datos. Pero no nos apuremos: todo eso lo vamos a ver con más detalle después.

Ahora, sobre variables: más adelante veremos que hay diferentes tipos. Una de las distinciones más importantes es entre variables **numéricas** (también llamadas *cuantitativas*) y **categóricas** (también llamadas *cualitativas*). ¿Todo bien? Sí, pero hay una trampa: como ya dijimos que existe investigación “cuantitativa” y “cualitativa”, es fácil que un estudiante piense que las variables cualitativas son solo para investigación cualitativa y que las cuantitativas son solo para investigación cuantitativa. **Y no. No tiene nada que ver.**

Por eso, en este libro vamos a preferir —cuando sea posible— usar los términos **numéricas** y **categóricas**. Así le hacemos la vida más fácil a los que recién están empezando. Porque hay muchas confusiones que no deberían existir, pero que siguen apareciendo solo por herencia lingüística.

Y hablando de confusiones, toca el turno de una palabra especialmente tramposa: **estadístico**. Este término puede referirse tanto a una persona que se dedica a la estadística como a un valor numérico calculado a partir de una muestra. O sea: **Ronald Fisher** era un estadístico porque se dedicaba a la estadística... pero también desarrolló el **estadístico F de Fisher**, que es una fórmula. ¿Qué tal? Para evitar ese enredo, yo voy a preferir usar el término **estadígrafo** para referirme al valor numérico. Así no mezclamos peras con ¿metales?, o personas con números.

Este tipo de ambigüedades no son raras. De hecho, son la norma. A veces heredamos traducciones apuradas del inglés, o palabras que suenan igual pero significan cosas distintas. Por ejemplo:

- “Alpha” puede referirse tanto a un criterio de significancia estadística (*alpha = 0.05*) como al famoso **coeficiente alfa de Cronbach** para evaluar confiabilidad de escalas. En algunos textos también aparece como *tasa de error tipo I*. Tres significados, un mismo símbolo.
- “Beta” puede ser el coeficiente de regresión estandarizado... o la tasa de error tipo II (probabilidad de no detectar un efecto cuando sí lo hay, o algo así).
- “R” puede ser la decimonovena letra del abecedario, pero también es el coeficiente de correlación de Pearson... o el nombre del software estadístico con el que probablemente trabajemos más adelante. 

Por eso, este libro va a ir comentando —cada vez que se cruce— esos lugares donde el lenguaje puede confundir más de lo que ayuda. Porque muchas veces el problema no es que no entiendas estadística: es que el sistema parece estar diseñado para marearte.

Y eso no puede ser.

Algunos de estos conceptos que acabamos de ver —población, muestra, variable, sujeto, dato, estadígrafo— son ladrillos básicos. No es necesario que los memorices como lista, pero sí que te familiarices con ellos, porque van a aparecer una y otra y otra vez.

Y si en el camino aparecen más conceptos, más nombres raros, más ambigüedades que suenan a contraseña encriptada... tranqui. Este libro está hecho para desenredarlos, para explicarlos con calma, con ejemplos, con comparaciones, y con las herramientas que mejor funcionen. Esto no es un culto de iniciados. Es un idioma. Y cuando lo hablás bien, cambia la forma en que piensas.


### 1.3 Advertencias

Este capítulo no es una nota amarga ni un bajón existencial. Es una advertencia cariñosa y necesaria. Porque no basta con aprender estadística. También hay que saber cuándo desconfiar. De los datos. De los discursos. Y —sobre todo— de cómo se mezclan.

La estadística es poderosa, pero esa misma potencia hace que se preste para el mal. Como una motosierra: corta árboles, pero también puede dejar la cagada si no se usa con juicio. Y en la historia de las ciencias sociales, de la política, del marketing e incluso de la salud pública, hay muchos ejemplos de mal uso, abuso y chamullo estadístico.

No es nuevo. Incluso hay frases célebres que lo dicen con tono burlón:

> “Existen tres tipos de mentiras: mentiras, malditas mentiras y estadísticas.”  
> *(atribuida a Mark Twain)*

> “Solo confío en las estadísticas que yo mismo he manipulado.”  
> *(atribuida a Churchill, pero probablemente inventada por alguien que perdió una elección y necesitaba un remate elegante)*

El punto es este: los datos no hablan por sí solos. Los interpreta alguien. Y ese alguien puede estar confundido, sesgado... o simplemente jugando para su propio equipo.

En mis años enseñando, he identificado varios perfiles clásicos del mal uso estadístico. No están en los manuales, pero sí en la vida real. Los presento acá con humor, pero el problema es serio.

Primero está el clásico borracho. Ese que se apoya en las estadísticas como quien se apoya en un poste de luz: no para iluminarse, sino para afirmarse. Tira un número sin contexto, lo lanza como argumento irrebatible y se va. Es fan de frases como “dato mata relato”, como si cualquier cifra —aunque esté mal medida o peor interpretada— fuera superior a cualquier análisis. Le encanta decir “está demostrado” y punto.

<!-- BEGIN:IMG -->
<figure>
  <img src="https://raw.githubusercontent.com/heelgueta/edesc/refs/heads/main/src/img/borracho.png" alt="borracho" width="188">
  <figcaption><p>Apunto de caer. Pero con Excel abierto.</p></figcaption>
</figure>
<!-- END:IMG -->

Después tenemos al payaso elegante. Tiene estilo, tiene presentación. Habla de regresiones, pone gráficos con colores que combinan, y cita papers que leyó a medias. Pero no entiende realmente lo que está haciendo. Confunde correlación con causalidad. Cree que el p-valor es un juicio final. Muestra tres decimales y asume que con eso gana la discusión. La forma es prolija, pero el fondo es espuma.

<!-- BEGIN:IMG -->
<figure>
  <img src="https://raw.githubusercontent.com/heelgueta/edesc/refs/heads/main/src/img/payaso.png" alt="payaso" width="188">
  <figcaption><p>El show debe continuar. Aunque los datos no den.</p></figcaption>
</figure>
<!-- END:IMG -->

Y claro, también está el estafador profesional. Este no se equivoca: sabe perfectamente lo que hace. Recorta los datos que le estorban, muestra sólo el gráfico que le conviene, mueve las escalas, exagera los efectos, omite la letra chica. Su objetivo no es analizar: es convencer. Puede estar vendiéndote un seguro, una política pública o una narrativa ideológica. No es torpeza, es estrategia.

<!-- BEGIN:IMG -->
<figure>
  <img src="https://raw.githubusercontent.com/heelgueta/edesc/refs/heads/main/src/img/estafador.png" alt="estafador" width="188">
  <figcaption><p>Cuando el gráfico ya viene con truco.</p></figcaption>
</figure>
<!-- END:IMG -->

Y a veces, ni siquiera hace falta mala fe. A veces los datos son simplemente débiles, ruidosos, mal recolectados, mal digitados, o irrelevantes para lo que se está preguntando. Pero alguien los agarra igual y se lanza a sacar conclusiones. Porque los tiene. Y claro, si metes basura en el análisis, el resultado no va a ser un milagro.

<!-- BEGIN:IMG -->
<figure>
  <img src="https://raw.githubusercontent.com/heelgueta/edesc/refs/heads/main/src/img/basura.png" alt="basura" width="188">
  <figcaption><p>Garbage in, garbage out.</p></figcaption>
</figure>
<!-- END:IMG -->

Por eso: aprender estadística no es aprender fórmulas. Es aprender a pensar. A oler cuando algo no cuadra. A detectar que falta información. A sospechar de los discursos cerrados y de los números que parecen mágicamente convincentes.

No es que todo sea mentira. Pero no todo lo que parece ciencia lo es. Y hay discursos que usan numeritos como maquillaje: para sonar modernos, para justificar decisiones cuestionables, para cerrar debates que deberían seguir abiertos.

Frente a eso, lo que necesitamos no es desconfianza cínica, sino pensamiento crítico bien afilado. La estadística, bien enseñada y bien usada, no es una trampa. Es una brújula. No te dice con certeza qué hacer, pero sí te ayuda a orientarte mejor.

Así que no se trata sólo de aprender a calcular: se trata de aprender a **entender** cuándo, cómo y por qué estamos midiendo algo. Quién lo mide. Para qué. Con qué consecuencias.

Ahí empieza el verdadero aprendizaje. Y empieza ahora.

## 2. Organizar

Hasta ahora hemos hablado de definiciones generales, del sentido de hacer ciencia con datos, y de por qué vale la pena aprender estadística. Pero ahora es momento de poner las manos en la masa. Si queremos analizar datos, necesitamos primero **organizar** esos datos. No es trivial. Hay que tener los ingredientes y utensilios a nuestro alcance antes de cocinar.

Esta sección está dedicada a entender qué son los datos, cómo se estructuran, qué tipos de variables existen, y cómo armar una matriz de datos que tenga sentido.

### 2.1 Datos

En el lenguaje cotidiano, la palabra "dato" puede significar cualquier cosa. "Oye, tengo un dato" puede ser una picada para comer, un cahuín, una anécdota, un secreto, o simplemente una opinión disfrazada. Y está bien. En una conversación entre amigxs, nadie necesita ponerse técnico. Pero cuando entramos al terreno del análisis académico, profesional o científico, tenemos que establecer ciertas convenciones. No para censurar el lenguaje coloquial, sino para **asegurar que estamos hablando de lo mismo**.

En estadística aplicada, un **dato** no es simplemente un número suelto ni una tabla cualquiera. Es un **valor con un contexto** que le da significado. Es información recolectada de forma sistemática, mediante un procedimiento más o menos definido, con un propósito investigativo. Puede ser el valor en una celda... pero esa celda pertenece a una tabla, que pertenece a un estudio, que fue hecho con una pregunta en mente. Sin ese marco, no es un dato: es solo ruido.

Además, los datos **no existen en el vacío**. Son registros sobre algo o alguien. En los estudios cuantitativos, los datos se refieren a *sujetos* (también llamados unidades de análisis) observados a través de ciertas *variables* que, de algún procedimiento definido, fueron registradas o medidas. Esos sujetos pueden ser personas, animales, organizaciones, países, canciones, piedras o sillas.

Lo que define qué constituye un "sujeto" en un estudio depende totalmente del diseño y propósito de ese estudio. Si es una investigación sobre estrategias pedagógicas, tiene sentido estudiar a estudiantes, o a docentes. Si es un estudio sobre nutrición infantil, tiene sentido que los sujetos sean niñxs, y quizás también sus cuidadores. En otro estudio podrían ser regiones, instituciones, barrios. Pero lo importante es que **en un mismo estudio, las unidades de análisis estén al mismo nivel lógico**. No tiene mucho sentido mezclar 231 personas, 23 frutas y 3 planetas en una misma base de datos, a menos que estemos haciendo una obra de teatro o una performance artística. En la investigación cuantitativa, la comparabilidad entre casos importa.

Esa decisión —sobre qué constituye un sujeto y qué variables se registran de él— es una de las más importantes y a veces más invisibles en toda investigación. Pensar bien los datos **empieza mucho antes de tenerlos**. Empieza en la claridad conceptual y metodológica del diseño.

### 2.2 Variables

Una **variable** es una característica, atributo, situación o dimensión relevante del sujeto bajo estudio. Es decir, aquello que cambia de un sujeto a otro y que decidimos observar. Las variables que escogemos dependen de nuestro marco teórico, nuestras herramientas metodológicas, nuestros sesgos, nuestras preguntas, nuestra ideología, nuestra curiosidad.

Y eso está bien.

No podemos —ni debemos— estudiar *todas* las variables posibles. Nadie lo hace. Siempre estamos dejando cosas fuera. El punto es **dejar fuera lo que no importa tanto** para enfocarnos en lo que sí nos puede decir algo valioso. Y eso requiere criterio, claridad y honestidad.

¿Tiene sentido medir la longitud exacta en centímetros de la uña izquierda del dedo meñique del pie de cada sujeto? Probablemente no... a menos que tu estudio sea sobre crecimiento ungular en condiciones extremas. Pero si estás haciendo un estudio sobre habilidades aritméticas, probablemente esa variable no aporta. El dato puede existir, pero eso no lo convierte en relevante. Seleccionar variables es **filtrar la realidad**. No es reducirla al absurdo, es enfocarla. Las galaxias también son complejas, y las estudiamos con variables.

La ciencia no es un espejo total de lo real: es una herramienta para recortar lo irrelevante y entender lo importante. Eso no la hace menos poderosa. La hace más útil.

#### Rol

Una de las primeras cosas que necesitamos entender al mirar nuestras variables es que **no todas cumplen el mismo papel** en una investigación. Y ojo: esto no es solo un tecnicismo. Es parte fundamental de pensar bien. Porque si no tienes claro qué rol cumple una variable, es como si tuvieras una banda donde cada instrumento toca una melodía distinta. Puede sonar interesante un rato... pero no es música. Es caos.

El “rol” de una variable se refiere al lugar que ocupa dentro del razonamiento de un estudio. ¿Es algo que queremos explicar? ¿Es algo que creemos que lo explica? ¿Es algo que podríamos ignorar, pero sospechamos que está interfiriendo? ¿O es simplemente una etiqueta auxiliar que usamos para mantener el orden? Todo eso importa.

En los estudios **experimentales** —esos donde el/la investigadxr controla activamente qué pasa y cómo— hay una distinción clásica que probablemente ya escuchaste: variables independientes (VI) y variables dependientes (VD).

La **variable independiente** es la que el investigador manipula deliberadamente o define como un factor que se sospecha causa algo. No es que sea “libre” en un sentido metafísico: es “independiente” porque no depende de otra cosa dentro del estudio. La **variable dependiente**, en cambio, es la que se observa o mide para ver si cambia en respuesta a la otra.

Tomemos un ejemplo simple: imaginemos un experimento donde queremos saber si escuchar música antes de una prueba mejora el rendimiento académico. Podemos dividir a los participantes en dos grupos: uno escucha música clásica antes de rendir una prueba, y el otro no escucha nada. Aquí, la VI es la música (presente vs. ausente) y la VD es el puntaje obtenido en la prueba.

{% hint style="info" %}
En español usamos “VI” y “VD”, pero en inglés también es común encontrar “IV” (independent variable) y “DV” (dependent variable).
{% endhint %}

Ahora bien, este lenguaje está pensado para estudios experimentales. Pero en estudios no experimentales (también llamados *correlacionales*), muchas veces especulamos con relaciones similares sin manipular nada. En ese contexto, lo correcto sería hablar de **variable predictora** (VP) y **variable criterio** (VC). Una predice, la otra es el resultado que intentamos explicar.

¿Y usamos bien estos términos? En teoría, sí. En la práctica... muchas veces se confunden, y se usan los de estudios experimentales aunque el diseño no lo sea. No es el fin del mundo, pero conviene tener claro que hay una diferencia. Y que esa diferencia no es solo semántica: habla de cómo concebimos las relaciones entre las cosas que estudiamos.

Más allá de estas distinciones, hay muchos otros roles que una variable puede tener:

A veces, hay variables que no son las que nos interesan directamente, pero que sí sabemos que podrían influir en los resultados. En esos casos, intentamos **controlarlas**: o bien manteniéndolas constantes, o bien midiéndolas y usándolas como **covariables** dentro del análisis. Por ejemplo, si estoy estudiando el efecto del ejercicio sobre la calidad del sueño, y sé que la edad influye en ambas cosas, puedo controlarla para que no distorsione los resultados.

También hay variables **moderadoras**, que cambian la relación entre otras variables. Por ejemplo, una intervención educativa puede ser más efectiva en estudiantes con alta motivación que en quienes no la tienen. Y hay **mediadoras**, que explican cómo ocurre un efecto. Si hacer deporte reduce la depresión porque mejora la autoestima, entonces la autoestima está mediando ese efecto.

Por otro lado, están las **variables extrañas**. Aquellas que no estaban en el radar, no se midieron, no se controlaron... pero que de alguna manera se cuelan en los resultados. Un cambio de clima, un escándalo mediático el día anterior, el ruido de una construcción cercana durante la aplicación del instrumento. No siempre podemos anticiparlas. Pero sí podemos estar atentos a su posibilidad.

Finalmente, hay variables que usamos solo para identificar o mantener el orden: número de folio, código de caso, grupo asignado, etc. No las analizamos, pero sin ellas sería un caos. Son variables auxiliares. Son como los nombres de los archivos: no dicen nada del contenido, pero permiten encontrarlo.

Pensar bien el rol de las variables no es sólo un ejercicio técnico. Es parte de tener claridad sobre lo que estás haciendo y por qué. De lo contrario, puedes terminar interpretando relaciones que no existen, u omitiendo cosas que sí importan.

Organizar no es solo ordenar. Es **hacer visible lo que importa**. Y eso empieza, siempre, por saber qué rol cumple cada cosa que medimos.

#### Naturaleza

Otra forma fundamental de clasificar las variables —y una de las más útiles al momento de analizarlas— tiene que ver con la **naturaleza del dato que producen**. Es decir, con el tipo de información que entregan cuando se miden. Aquí entramos a una distinción clásica: **variables numéricas** versus **variables categóricas**.

Una **variable numérica** (a veces llamada *cuantitativa*) es aquella que genera valores numéricos con los que tiene sentido realizar operaciones aritméticas. Por ejemplo: sumar, restar, calcular promedios, analizar desviaciones. Variables como la **edad**, el **ingreso mensual**, el **peso corporal**, o el **tiempo de reacción** son ejemplos típicos: no sólo se expresan con números, sino que además esos números representan cantidades medibles.

Una **variable categórica** (también llamada *cualitativa*) no se presta para hacer ese tipo de cálculos. En vez de números que significan "cuánto", entrega categorías que significan "cuál". Ejemplos: **sexo/género**, **tipo de música favorita**, **región de residencia**, **diagnóstico clínico**. A veces esas categorías están etiquetadas con números —como cuando 1 = masculino, 2 = femenino— pero eso no significa que el 2 "valga más" que el 1. Son sólo etiquetas.

{% hint style="info" %}
Este libro prefiere hablar de **variables numéricas** y **categóricas** en vez de cuantitativas y cualitativas, para evitar una confusión común: pensar que las variables cualitativas se estudian solo con metodología cualitativa, o que lo cuantitativo se reduce a las variables cuantitativas. En realidad, muchos estudios cuantitativos usan variables de ambos tipos. Y el lenguaje claro ayuda.
{% endhint %}

Dentro de las variables numéricas podemos hacer una distinción adicional:

- Las **variables continuas** son aquellas que pueden tomar *cualquier valor dentro de un rango*. No hay "saltos" entre valores posibles. Ejemplo clásico: la **estatura**. Podés medirla en metros, en centímetros, en milímetros, e incluso con decimales. Cuanto más precisa sea tu herramienta, más cifras podés registrar. Si alguien mide 1,72 m, no hay ningún problema en pensar que otra persona puede medir 1,725 m.

- Las **variables discretas**, en cambio, toman valores contables y no tienen valores intermedios entre ellos. Como cuando contamos **número de hijos**, **cantidad de veces que fuiste al cine este mes**, o **cuántas tazas de café tomaste esta semana**. Nadie tomó 2,37 tazas de café. O tomaste 2, o tomaste 3. (Si tomaste media taza, igual cuenta como 1.)

Pero —y esto es clave— **la distinción no siempre es tan clara**. Por ejemplo: la **edad**. En muchos estudios se registra como un número entero (años cumplidos), pero perfectamente podríamos medirla con más precisión: años con decimales, meses, semanas, días. Para un pediatra, un bebé puede tener 1,3 semanas de edad. Para un estudio de adultos mayores, el año es suficiente. Así que una misma variable puede tratarse como continua o discreta, según el contexto.

¿Y qué pasa con variables como el **RUT**? Tiene números, sí, pero ¿es una variable numérica? No necesariamente. El RUT no se usa para sumar, promediar o calcular desviaciones. Es un identificador. Más aún: si incluye letras (como la K del dígito verificador), ya ni siquiera es numérico en forma. Este tipo de variables son auxiliares, sirven para **identificar casos**, y muchas veces el software las trata como *categóricas*, aunque no describan una característica en sentido estricto.

Entonces, ¿por qué es importante esta clasificación? Porque **el tipo de variable condiciona qué herramientas estadísticas podemos usar**. Si una variable es numérica, vamos a poder calcular promedios, desviaciones, correlaciones, histogramas. Si es categórica, vamos a poder hacer tablas de frecuencia, proporciones, gráficos de barras, etc. No se trata de imponer una regla, sino de usar el método que tiene sentido para el tipo de dato que tenemos.

Y aunque hay muchas excepciones y bordes difusos —como veremos más adelante con las variables "cuasicuantitativas"—, la distinción entre numéricas y categóricas ya nos da una base importante para organizar y pensar nuestros análisis.

#### Medida

Para precisar aún más el tratamiento de las variables, se suele recurrir a una idea propuesta por el psicólogo Stanley Stevens en 1946 y refinada en 1958: la distinción entre **niveles de medición** o **escalas de medida**. Según esta clasificación, las variables pueden ser de cuatro tipos:

- **Nominales**: categóricas sin orden. Agrupan, pero no jerarquizan. Ejemplo: color de ojos, nacionalidad, tipo de sangre. Si alguien es tipo A y otro tipo B, no hay un "más" o "menos", sólo son diferentes.

- **Ordinales**: categóricas *con* orden. Aquí sí hay jerarquía, aunque las distancias entre categorías no sean iguales. Ejemplo: nivel educacional, satisfacción ("bajo", "medio", "alto"), frecuencia ("nunca", "a veces", "siempre"). Sabemos cuál viene antes y cuál después, pero no cuánto más.

- **Intervalo**: numéricas con distancias iguales entre valores, pero *sin un cero absoluto*. Ejemplo típico: temperatura en grados Celsius. El salto de 10°C a 20°C es igual al de 20°C a 30°C, pero 0°C no significa "nada de temperatura", simplemente es un punto arbitrario.

- **Razón**: numéricas con distancia y un cero real. Ejemplo: peso, altura, ingresos. Acá sí tiene sentido decir que algo pesa el doble que otra cosa. El cero indica ausencia de lo medido. 

Una analogía posible es esta: las variables nominales son **cajones**, donde cada cosa está en su compartimiento; las ordinales son **escaleras**, donde los peldaños tienen un orden claro pero no siempre sabemos qué tan alto es cada uno; las de intervalo son **reglas sin punto de inicio**; y las de razón, **reglas con punto cero real**, que permiten hablar de proporciones.

La mayoría de las veces, las variables nominales y ordinales coinciden con las categóricas, y las de intervalo y razón, con las numéricas. Pero no es una regla estricta. Por ejemplo, las escalas tipo **Likert** (muy comunes en psicología y ciencias sociales) son técnicamente ordinales, pero muchas veces se analizan como si fueran numéricas. A eso se les llama a veces **variables cuasicuantitativas**: ordinales numéricas tratadas *como si* fueran de razón, con justificaciones prácticas.

{% hint style="info" %}
El estadístico E. Lord (1953) lo dijo con elegancia: *“los números no saben de dónde vinieron”*. Es decir, un número por sí solo no dice nada. Lo importante no es la cifra, sino lo que representa. Por eso las escalas de medida son guías, no dogmas. Sirven para pensar con claridad, pero no hay que forzarlas como si fueran leyes inmutables.
{% endhint %}

Y por supuesto, esta clasificación tiene consecuencias prácticas. ¿Qué hacemos con una variable nominal? Tablas de frecuencia, gráficos de barra, proporciones. ¿Y con una ordinal? Casi lo mismo, pero con más cuidado respecto al orden. ¿Y si es de intervalo o razón? Ahí ya se justifica usar medias, desviaciones estándar, histogramas, modelos estadísticos.

Además, **algunos programas de software estadístico simplifican esta clasificación**. Por ejemplo, SPSS, JASP o Jamovi no distinguen entre variables de intervalo y de razón: las agrupan en una sola categoría llamada *escalar*. Y también incluyen una categoría llamada *identificación*, que sirve para variables que no se analizan directamente, pero ayudan a organizar la base (como el RUT o un código de participante).

Esto no es un error: es una convención. Y como toda convención, lo importante no es que sea perfecta, sino que sepamos usarla bien.

### 2.3 Matriz

Una vez que entendemos qué son los datos, qué representan, y qué tipo de variables estamos registrando, llega el momento de **organizarlos bien**. No basta con tener la información: hay que disponerla de forma que se pueda leer, analizar y compartir. Para eso usamos lo que se llama una **matriz de datos**, también conocida como *dataset*, *base de datos*, o incluso simplemente *tabla*.

#### Orden

La forma más común y recomendada de organizar los datos en estadística aplicada es lo que llamamos formato **tidy** (ordenado, limpio). ¿Qué significa esto?

- Cada **fila** representa un **sujeto distinto** (persona, caso, unidad de análisis).
- Cada **columna** representa una **variable distinta**.
- Cada **celda** contiene un **dato específico**: el valor de una variable para un sujeto.

Este formato no es caprichoso: es el que mejor funciona con casi todos los programas de análisis de datos, y además **tiene sentido lógico**. Es como una planilla bien hecha: podés leerla de izquierda a derecha (comparar variables dentro de un caso) o de arriba hacia abajo (ver cómo se distribuye una variable entre distintos casos).

[INSERTAR IMAGEN DE MATRIZ TIDY]  
*Caption: Estructura típica de una matriz tidy: sujetos en filas, variables en columnas.*

Pero ojo: no todos los datos vienen así desde el principio. A veces están desordenados, mal estructurados, con nombres larguísimos, o con formatos extraños. Y si no los organizamos bien desde el inicio, **vamos a sufrir después**. Por eso conviene establecer ciertas buenas prácticas desde el comienzo.

Por ejemplo:

- **Nombres de variables**: deben ser cortos, claros, sin tildes ni espacios. Si una variable se llama “Edad (años cumplidos al momento de la recolección)”, podés acortarla a `edad` y guardar la definición completa en otro lado (eso se llama **metadato**: dato sobre los datos).
- **Formato homogéneo**: si una columna mezcla números con letras, probablemente el software se vuelva loco. Si una variable es numérica, que todos los valores sean numéricos.
- **Una tabla, una unidad de análisis**: no mezcles personas con países o canciones. Cada matriz debe tener un sujeto consistente.

Si se te ocurre una forma más linda o creativa de organizar, bacán. Pero mientras no tengas una razón muy buena, **mejor seguir el formato estándar**. No por conservadurismo, sino porque funciona.

#### Software

Los datos pueden manejarse en muchas plataformas. Algunas son muy conocidas y están en casi todos los computadores:

- **Excel** o **Google Sheets**: accesibles, visuales, útiles para bases pequeñas o medianas. Muy buenas para comenzar.
- **LibreOffice Calc**: alternativa libre y gratuita.
- **SPSS**: software clásico en ciencias sociales, con interfaz amigable, pero no libre.
- **Jamovi** o **JASP**: programas libres, pensados para ser amigables y poderosos a la vez. Permiten análisis complejos sin necesidad de programar.
- **R y Python**: lenguajes de programación. Requieren más curva de aprendizaje, pero ofrecen total flexibilidad y transparencia.

No tenés que aprenderlos todos. Pero sí **alguno**. Y lo ideal es que sea uno que te permita *ver* lo que estás haciendo y *entender* cómo fluye el análisis. Este libro intentará usar ejemplos que sean traducibles a varios formatos, y en especial mostrar cómo se vería el proceso en contextos reales.

#### Formatos

Además del software que usamos, hay que entender los **formatos de archivo** en los que los datos se guardan. Esto es clave para compartir, abrir, exportar o simplemente no perder lo que hiciste.

Algunos formatos son específicos de programas:

- `.sav`: de SPSS.
- `.omv`: de Jamovi.
- `.jasp`: de JASP.
- `.xlsx`: de Excel.

Otros son **más universales**, y por lo tanto más recomendables para compartir:

- `.csv` (comma-separated values): texto plano donde cada columna está separada por comas. Muy liviano y legible.
- `.tsv` (tab-separated values): igual, pero separado por tabulaciones.
- `.json` o `.xml`: formatos estructurados, muy usados para datos en la web o APIs.
- `.sql`, `.parquet`, `.feather`: formatos más técnicos, usados para bases grandes o procesos automáticos.

[INSERTAR TABLA COMPARATIVA DE FORMATOS]  
*Caption: Comparación entre formatos de archivo según tipo, legibilidad, compatibilidad y peso.*

¿Por qué importa esto? Porque **el análisis no es el único paso**. Muchas veces tenés que mandar tus datos a otra persona, guardarlos por años, usarlos en otro software, o procesarlos automáticamente. Saber en qué formato están, y cómo transformarlos, es parte del trabajo.

Y por último —pero no menos importante— una advertencia:

Si los datos están mal desde el inicio, ninguna herramienta los va a salvar. Si registraste mal, si escribiste nombres distintos para una misma categoría, si mezclaste fechas con textos... después vas a perder horas arreglando lo que podrías haber hecho bien de entrada.

Eso tiene un nombre: **GIGO**. *Garbage In, Garbage Out*.

<!-- BEGIN:IMG -->
<figure>
  <img src="https://raw.githubusercontent.com/heelgueta/edesc/refs/heads/main/src/img/basura.png" alt="basura" width="188">
  <figcaption><p>Garbage in, garbage out.</p></figcaption>
</figure>
<!-- END:IMG -->

Por eso esta sección se llama “Organizar”. Porque no se trata solo de juntar datos, sino de darles forma, estructura y sentido. Como quien ordena su pieza antes de ponerse a estudiar: no porque sea un ritual, sino porque un espacio ordenado **ayuda a pensar mejor**.

No se trata de rigidez, sino de claridad. No de reglas inamovibles, sino de convenciones que nos hacen la vida más fácil. La organización de los datos no es un paso previo: es el primer paso para pensar con orden. Y pensar con orden es pensar mejor.


## 3. Resumir

<!--force-render-->

_(Sección en desarrollo: **3. Resumir**)_

---

### Frecuencia

<!--force-render-->
[[componente:tabs:p1331]]

_(Sección en desarrollo: **Frecuencia**)_

---

### Tendencia

<!--force-render-->

_(Sección en desarrollo: **Tendencia**)_

---

#### Moda

<!--force-render-->

_(Sección en desarrollo: **Moda**)_

---

#### Media

<!--force-render-->

_(Sección en desarrollo: **Media**)_

---

#### Mediana

<!--force-render-->

_(Sección en desarrollo: **Mediana**)_

---

### Gráficos

<!--force-render-->

_(Sección en desarrollo: **Gráficos**)_

---

#### Barra simple

<!--force-render-->

_(Sección en desarrollo: **Barra simple**)_

---

#### Sectores

<!--force-render-->

_(Sección en desarrollo: **Sectores**)_

---

#### Horrores

<!--force-render-->

_(Sección en desarrollo: **Horrores**)_

---

#### Accesibilidad

<!--force-render-->

_(Sección en desarrollo: **Accesibilidad**)_

---

#### Histograma

<!--force-render-->

_(Sección en desarrollo: **Histograma**)_

---

#### Otros


https://developers.google.com/chart/interactive/docs/gallery
https://r-graph-gallery.com/
https://python-graph-gallery.com/
https://seaborn.pydata.org/examples/index.html
https://plotly.com/python/

Bonus: Espectograma?

---
### Desafíos

<!--force-render-->

_(Sección en desarrollo: **Desafíos**)_

